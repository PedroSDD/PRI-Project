from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from operator import itemgetter

def score_candidates(filename):

    file_name = open(filename)
    train = fetch_20newsgroups(subset='train')
    vectorizer = TfidfVectorizer(use_idf=False, stop_words='english', ngram_range=(1, 3))
    vectorizer.fit_transform(train.data)
    my_doc_tfidf = vectorizer.transform(file_name)

    feature_names = vectorizer.get_feature_names()
    dense = my_doc_tfidf.todense()
    densed_idf = dense[0].tolist()[0]
    scores = zip(range(0, len(densed_idf)), densed_idf)
    feature_sorted = sorted(scores, key=itemgetter(1))[-5:]

    feature_name_sorted = []
    key_phrases_dic = {}

    for pair in feature_sorted:
        feature_name_sorted.append(feature_names[pair[0]])

    for word in feature_name_sorted:
        key_phrases_dic[word] = 0

    print key_phrases_dic
    return key_phrases_dic

def phrases_spliter(filename):
    list_phrases = []
    with open(filename, 'r') as file:
        all_phrases = file.read().strip().split('.')
        for words in all_phrases:
            list_phrases.append(words.split())
        return list_phrases


def create_graph(list_phrases, key_phrases_dic):
    graph = {}
    list_keywords_phrase = []
    for phrase in list_phrases:
        for word in phrase:
            if word in key_phrases_dic:
                list_aux.append(word)
                graph[word] = list_keywords_phrase
        list_keywords_phrase = []
    return graph

def initializer():
    key_phrase_dic = score_candidates('teste')
    res2 = phrases_spliter('teste')
    create_graph(res2, key_phrase_dic)

initializer()

